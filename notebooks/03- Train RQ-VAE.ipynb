{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f19a022-2b13-462f-97cf-37d1d0aaa8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import wandb\n",
    "from tiger.data.sentence_embedding import SentenceEmbeddingsDataset\n",
    "from tiger.distributions.gumbel import TemperatureScheduler\n",
    "from tiger.models.semantic_id import RQVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b048cac2-2e55-41fb-bdbc-92c90640bd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a32bba-eeb5-4593-8861-bbf2019e17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "LR = 0.0004\n",
    "MAX_LR = 0.01\n",
    "NUM_EPOCHS = 2000\n",
    "BETA = 0.25\n",
    "CODEBOOK_SIZES = [256, 256, 256]\n",
    "LATENT_DIM = 32\n",
    "USE_GUMBEL=True\n",
    "TEMP = 1\n",
    "MIN_TEMP = 0.01\n",
    "ANNEAL_RATE = 0.00003\n",
    "STEP_SIZE = 20\n",
    "EMBEDDING_LOCATION = \"../data/processed/2014/Beauty_sentence_embeddings.npy\"\n",
    "VAL_SPLIT = 0.05\n",
    "T5_DIM = 768\n",
    "NuM_CODEBOOKS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7dcfcd-1d07-428f-ba9c-8868c293406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamrit\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/notebooks/wandb/run-20241116_210151-09wy0pys</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amrit/tiger-semantic-id/runs/09wy0pys' target=\"_blank\">sage-pyramid-21</a></strong> to <a href='https://wandb.ai/amrit/tiger-semantic-id' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/amrit/tiger-semantic-id' target=\"_blank\">https://wandb.ai/amrit/tiger-semantic-id</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/amrit/tiger-semantic-id/runs/09wy0pys' target=\"_blank\">https://wandb.ai/amrit/tiger-semantic-id/runs/09wy0pys</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(key=wandb_key)\n",
    "run = wandb.init(\n",
    "    project=\"tiger-semantic-id\",\n",
    "    config={\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"lr\": LR,\n",
    "        \"max_lr\": MAX_LR,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"beta\": BETA,\n",
    "        \"codebook_sizes\": CODEBOOK_SIZES,\n",
    "        \"latent_dim\": LATENT_DIM,\n",
    "        \"temp\": TEMP,\n",
    "        \"min_temp\": MIN_TEMP,\n",
    "        \"anneal_rate\": ANNEAL_RATE,\n",
    "        \"step_size\": STEP_SIZE,\n",
    "        \"embedding_location\": EMBEDDING_LOCATION,\n",
    "        \"val_split\": VAL_SPLIT,\n",
    "        \"use_gumbel\": USE_GUMBEL\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650ded2a-742e-4fdc-801d-be82d2e408ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codebook_usage(model, dataloader):\n",
    "    model.eval()\n",
    "    sem_id_list = []\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(\"cuda\")\n",
    "        _, sem_ids, _ = model.get_semantic_ids(batch, TEMP)\n",
    "        sem_id_list.append(sem_ids)\n",
    "    \n",
    "    sem_ids = torch.cat(sem_id_list, dim=0)\n",
    "    df = pd.DataFrame(sem_ids.cpu())\n",
    "    cb_1 = df[0].value_counts().shape[0]\n",
    "    cb_2 = df[1].value_counts().shape[0]\n",
    "    cb_3 = df[2].value_counts().shape[0]\n",
    "    perc = (cb_1 + cb_2 + cb_3) / sum(CODEBOOK_SIZES)\n",
    "    return (cb_1, cb_2, cb_3), perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23a7c35-c55e-4c15-8faf-3b808182da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(EMBEDDING_LOCATION)\n",
    "train, val = train_test_split(embeddings, test_size=VAL_SPLIT)\n",
    "\n",
    "train_dataset = SentenceEmbeddingsDataset(torch.from_numpy(train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, prefetch_factor=2, pin_memory=True, num_workers=4)\n",
    "\n",
    "val_dataset = SentenceEmbeddingsDataset(torch.from_numpy(val))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, prefetch_factor=2, pin_memory=True, num_workers=4)\n",
    "\n",
    "model = RQVAE(\n",
    "    codebook_sizes=CODEBOOK_SIZES,\n",
    "    input_dim=T5_DIM,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    beta=BETA,\n",
    "    use_gumbel=USE_GUMBEL\n",
    ")\n",
    "model = model.to('cuda')\n",
    "optimiser = optim.Adagrad(model.parameters(), lr=LR)\n",
    "# optimiser = optim.AdamW(model.parameters(), lr=LR)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimiser, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader), epochs=NUM_EPOCHS)\n",
    "temp_scheduler = TemperatureScheduler(TEMP, MIN_TEMP, ANNEAL_RATE, STEP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b2ae2b4-685d-4415-8641-9b831fe6ea63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 143, 234), 0.4921875)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_codebook_usage(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42536baf-e94c-4f29-86bb-35cb1c19233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145658b4baf94c7fa747d47f575c25e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code book usage: (256, 256, 254), perc: 99.7%\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    temp = temp_scheduler.get_temp(epoch)\n",
    "\n",
    "    if epoch == 0:\n",
    "        init_batch = next(iter(train_dataloader))\n",
    "        init_batch = init_batch.to(\"cuda\")\n",
    "        model.initialize_codebooks(init_batch)\n",
    "        cb_usage, perc = get_codebook_usage(model, train_dataloader)\n",
    "        print(f\"code book usage: {cb_usage}, perc: {perc:.1%}\")\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        batch = batch.to(\"cuda\")\n",
    "        optimiser.zero_grad()\n",
    "        loss = model(batch, temp)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        # scheduler.step()\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "    train_loss = train_running_loss / len(train_dataloader)\n",
    "    # wandb.log({\"train/loss\": train_loss, \"temp\": temp}, step=epoch)\n",
    "    wandb.log({\"train/loss\": train_loss}, step=epoch)\n",
    "\n",
    "    if epoch % 20 == 9:\n",
    "        val_running_loss = 0.0\n",
    "        model.eval()\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(\"cuda\")\n",
    "            val_loss = model(batch, temp)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "        val_loss = val_running_loss / len(val_dataloader)\n",
    "\n",
    "        cb_usage, perc = get_codebook_usage(model, train_dataloader)\n",
    "\n",
    "        wandb.log({\"val/loss\": val_loss, \"codebook_usage\": perc}, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e278ca79-91a5-466f-adf8-afc4a6b5bc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>codebook_usage</td><td>█████▇██▇▇▇▇▇▇▇▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁</td></tr><tr><td>train/loss</td><td>▇▇█▄▇▄▂▇▇▅▅▁▃▂▃█▇▃▁▄▆▃▆▃▂▃▆▁▃▇▂▃▆▅▅▁▅▄▂▂</td></tr><tr><td>val/loss</td><td>█▃▆▅▃▃▃▃▂▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▃▂▂▃▃▂▃▂▁▁▃▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>codebook_usage</td><td>0.69531</td></tr><tr><td>train/loss</td><td>0.15917</td></tr><tr><td>val/loss</td><td>0.1595</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-pyramid-21</strong> at: <a href='https://wandb.ai/amrit/tiger-semantic-id/runs/09wy0pys' target=\"_blank\">https://wandb.ai/amrit/tiger-semantic-id/runs/09wy0pys</a><br/> View project at: <a href='https://wandb.ai/amrit/tiger-semantic-id' target=\"_blank\">https://wandb.ai/amrit/tiger-semantic-id</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241116_210151-09wy0pys/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7792d56-8d50-4100-bd8e-0a147da91c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/rqvae_no_temp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4777d-8013-47db-9c8f-0e98ba1f9820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
